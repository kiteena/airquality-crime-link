{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "from google.cloud import bigquery\n",
    "from bq_helper import BigQueryHelper\n",
    "%load_ext google.cloud.bigquery\n",
    "import os\n",
    "# For visualization\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Spectral6, brewer\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"My Project-bbdce7b1712b.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_assistant = BigQueryHelper(\"bigquery-public-data\", \"epa_historical_air_quality\")\n",
    "\n",
    "## We are only looking at SF Data\n",
    "query=\"\"\"\n",
    "SELECT * FROM `bigquery-public-data.epa_historical_air_quality.co_daily_summary`\n",
    "where state_name =\"California\" AND city_name=\"San Francisco\"\n",
    "\"\"\"\n",
    "\n",
    "df = bq_assistant.query_to_pandas(query)\n",
    "##df=pd.read_csv('carbon-monoxide-results-20181007-145932.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 HOUR', '8-HR RUN AVG END HOUR'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample_duration.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the no of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_code                 0\n",
       "county_code                0\n",
       "site_num                   0\n",
       "parameter_code             0\n",
       "poc                        0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "datum                      0\n",
       "parameter_name             0\n",
       "sample_duration            0\n",
       "pollutant_standard         0\n",
       "date_local                 0\n",
       "units_of_measure           0\n",
       "event_type                 0\n",
       "observation_count          0\n",
       "observation_percent        0\n",
       "arithmetic_mean            0\n",
       "first_max_value            0\n",
       "first_max_hour             0\n",
       "aqi                    16396\n",
       "method_code            16398\n",
       "method_name                0\n",
       "local_site_name            0\n",
       "address                    0\n",
       "state_name                 0\n",
       "county_name                0\n",
       "city_name                  0\n",
       "cbsa_name                  0\n",
       "date_of_last_change        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Missing values in aqi ( Dont Uncomment this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "# imp=Imputer(missing_values='NaN',strategy='mean')\n",
    "\n",
    "# ## replace missing values in aqi and method code with mean\n",
    "# df[\"aqi\"]=imp.fit_transform(df[[\"aqi\"]]).ravel()\n",
    "# df[\"method_code\"]=imp.fit_transform(df[[\"method_code\"]]).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization ( for different years 1990-2017)\n",
    "\n",
    "We will measure average aqi for different gases (CO,O3,NO2,SO2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Graph for the average AQI over the years for the 4 gases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Spectral6, brewer\n",
    "from bokeh.transform import factor_cmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Air Quality Index for CO over the years in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM date_local) as year,\n",
    "        round(avg(aqi),2) as avg_aqi\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.co_daily_summary`\n",
    "    WHERE\n",
    "       state_name =\"California\" AND city_name=\"San Francisco\"\n",
    "    GROUP BY year\n",
    "    ORDER BY year ASC\n",
    "        \"\"\"\n",
    "df_co = bq_assistant.query_to_pandas(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co.year = df_co.year.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhileshchaudhary/anaconda3/lib/python3.6/site-packages/bokeh/models/mappers.py:82: UserWarning: Palette length does not match number of factors. ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017'] will be assigned to `nan_color` gray\n",
      "  warnings.warn(\"Palette length does not match number of factors. %s will be assigned to `nan_color` %s\" % (extra_factors, self.nan_color))\n"
     ]
    }
   ],
   "source": [
    "## Reference https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html\n",
    "## Bar graph\n",
    "output_file('average_aqi_CO_over_the_years.html')\n",
    "\n",
    "source = ColumnDataSource(df_co)\n",
    "years = source.data['year'].tolist()\n",
    "p = figure(x_range=years, plot_width=1200, plot_height=800)\n",
    "\n",
    "color_map = factor_cmap(field_name='year', palette=Spectral6, factors=years)\n",
    "\n",
    "p.vbar(x='year', top='avg_aqi', source=source, width=0.90)\n",
    "\n",
    "p.title.text ='Average AQI of Carbon monoxide in different years'\n",
    "p.xaxis.axis_label = 'Years'\n",
    "p.yaxis.axis_label = \"Average AQI of Carbon monoxide\"\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Air Quality Index for O3 over the years in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM date_local) as year,\n",
    "        round(avg(aqi),2) as avg_aqi\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.o3_daily_summary`\n",
    "    WHERE\n",
    "       state_name =\"California\" AND city_name=\"San Francisco\"\n",
    "    GROUP BY year\n",
    "    ORDER BY year ASC\n",
    "        \"\"\"\n",
    "df_o3 = bq_assistant.query_to_pandas(QUERY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o3.year = df_o3.year.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhileshchaudhary/anaconda3/lib/python3.6/site-packages/bokeh/models/mappers.py:82: UserWarning: Palette length does not match number of factors. ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017'] will be assigned to `nan_color` gray\n",
      "  warnings.warn(\"Palette length does not match number of factors. %s will be assigned to `nan_color` %s\" % (extra_factors, self.nan_color))\n"
     ]
    }
   ],
   "source": [
    "## Reference https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html\n",
    "## Bar graph\n",
    "output_file('average_aqi_O3_over_the_years.html')\n",
    "\n",
    "source = ColumnDataSource(df_o3)\n",
    "years = source.data['year'].tolist()\n",
    "p = figure(x_range=years, plot_width=1200, plot_height=800)\n",
    "\n",
    "color_map = factor_cmap(field_name='year', palette=Spectral6, factors=years)\n",
    "\n",
    "p.vbar(x='year', top='avg_aqi', source=source, width=0.90)\n",
    "\n",
    "p.title.text ='Average AQI of Ozone in different years'\n",
    "p.xaxis.axis_label = 'Years'\n",
    "p.yaxis.axis_label = \"Average AQI of Ozone\"\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Air Quality Index for NO2 over the years in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM date_local) as year,\n",
    "        round(avg(aqi),2) as avg_aqi\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.no2_daily_summary`\n",
    "    WHERE\n",
    "       state_name =\"California\" AND city_name=\"San Francisco\"\n",
    "    GROUP BY year\n",
    "    ORDER BY year ASC\n",
    "        \"\"\"\n",
    "df_no2 = bq_assistant.query_to_pandas(QUERY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no2.year = df_no2.year.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhileshchaudhary/anaconda3/lib/python3.6/site-packages/bokeh/models/mappers.py:82: UserWarning: Palette length does not match number of factors. ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017'] will be assigned to `nan_color` gray\n",
      "  warnings.warn(\"Palette length does not match number of factors. %s will be assigned to `nan_color` %s\" % (extra_factors, self.nan_color))\n"
     ]
    }
   ],
   "source": [
    "## Reference https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html\n",
    "## Bar graph\n",
    "output_file('average_aqi_no2_over_the_years.html')\n",
    "\n",
    "source = ColumnDataSource(df_no2)\n",
    "years = source.data['year'].tolist()\n",
    "p = figure(x_range=years, plot_width=1200, plot_height=800)\n",
    "\n",
    "color_map = factor_cmap(field_name='year', palette=Spectral6, factors=years)\n",
    "\n",
    "p.vbar(x='year', top='avg_aqi', source=source, width=0.90)\n",
    "\n",
    "p.title.text ='Average AQI of Nitrogen dioxide  in different years'\n",
    "p.xaxis.axis_label = 'Years'\n",
    "p.yaxis.axis_label = \"Average AQI of Nitrogen dioxide \"\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhileshchaudhary/anaconda3/lib/python3.6/site-packages/bokeh/models/mappers.py:82: UserWarning: Palette length does not match number of factors. ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008'] will be assigned to `nan_color` gray\n",
      "  warnings.warn(\"Palette length does not match number of factors. %s will be assigned to `nan_color` %s\" % (extra_factors, self.nan_color))\n"
     ]
    }
   ],
   "source": [
    "##Avg Air Quality Index for SO2 over the years in San Francisco\n",
    "\n",
    "QUERY = \"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM date_local) as year,\n",
    "        round(avg(aqi),2) as avg_aqi\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.so2_daily_summary`\n",
    "    WHERE\n",
    "       state_name =\"California\" AND city_name=\"San Francisco\"\n",
    "    GROUP BY year\n",
    "    ORDER BY year ASC\n",
    "        \"\"\"\n",
    "df_so2 = bq_assistant.query_to_pandas(QUERY)\n",
    "\n",
    "df_so2.year = df_so2.year.astype(str)\n",
    "\n",
    "## Reference https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html\n",
    "## Bar graph\n",
    "output_file('average_aqi_so2_over_the_years.html')\n",
    "\n",
    "source = ColumnDataSource(df_so2)\n",
    "years = source.data['year'].tolist()\n",
    "p = figure(x_range=years, plot_width=1200, plot_height=800)\n",
    "\n",
    "color_map = factor_cmap(field_name='year', palette=Spectral6, factors=years)\n",
    "\n",
    "p.vbar(x='year', top='avg_aqi', source=source, width=0.90)\n",
    "\n",
    "p.title.text ='Average AQI of Sulphur dioxide  in different years'\n",
    "p.xaxis.axis_label = 'Years'\n",
    "p.yaxis.axis_label = \"Average AQI of Sulphur dioxide \"\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Air Quality Index for Particulate Matter over the years in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhileshchaudhary/anaconda3/lib/python3.6/site-packages/bokeh/models/mappers.py:82: UserWarning: Palette length does not match number of factors. ['2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017'] will be assigned to `nan_color` gray\n",
      "  warnings.warn(\"Palette length does not match number of factors. %s will be assigned to `nan_color` %s\" % (extra_factors, self.nan_color))\n"
     ]
    }
   ],
   "source": [
    "##Avg Air Quality Index for Particulate Matter over the years in San Francisco\n",
    "\n",
    "QUERY = \"\"\"\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM date_local) as year,\n",
    "        round(avg(aqi),2) as avg_aqi\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.pm25_frm_daily_summary`\n",
    "    WHERE\n",
    "       state_name =\"California\" AND city_name=\"San Francisco\"\n",
    "    GROUP BY year\n",
    "    ORDER BY year ASC\n",
    "        \"\"\"\n",
    "df_pm25 = bq_assistant.query_to_pandas(QUERY)\n",
    "\n",
    "df_pm25.year = df_pm25.year.astype(str)\n",
    "\n",
    "## Reference https://bokeh.pydata.org/en/latest/docs/user_guide/categorical.html\n",
    "## Bar graph\n",
    "output_file('average_aqi_pm25_over_the_years.html')\n",
    "\n",
    "source = ColumnDataSource(df_pm25)\n",
    "years = source.data['year'].tolist()\n",
    "p = figure(x_range=years, plot_width=1200, plot_height=800)\n",
    "\n",
    "color_map = factor_cmap(field_name='year', palette=Spectral6, factors=years)\n",
    "\n",
    "p.vbar(x='year', top='avg_aqi', source=source, width=0.90)\n",
    "\n",
    "p.title.text ='Average AQI of Particulate Matter in different years'\n",
    "p.xaxis.axis_label = 'Years'\n",
    "p.yaxis.axis_label = \"Average AQI of Particulate Matter\"\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RENAME THE COLUMNS OF THE 5 DFS \n",
    "## https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "df_co.rename(columns={'avg_aqi': 'avg_aqi_CO'},inplace=True)\n",
    "df_no2.rename(columns={'avg_aqi': 'avg_aqi_NO2'},inplace=True)\n",
    "df_o3.rename(columns={'avg_aqi': 'avg_aqi_O3'},inplace=True)\n",
    "df_so2.rename(columns={'avg_aqi': 'avg_aqi_SO2'},inplace=True)\n",
    "df_pm25.rename(columns={'avg_aqi': 'avg_aqi_PM25'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the Time Series Graphs of all the 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the dataframes ie all 3\n",
    "from functools import reduce\n",
    "\n",
    "## Reference: https://stackoverflow.com/questions/23668427/pandas-three-way-joining-multiple-dataframes-on-columns\n",
    "frames=[df_co,df_no2,df_o3]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='year'), frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>avg_aqi_CO</th>\n",
       "      <th>avg_aqi_NO2</th>\n",
       "      <th>avg_aqi_O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>26.14</td>\n",
       "      <td>33.20</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>25.52</td>\n",
       "      <td>36.59</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>23.96</td>\n",
       "      <td>32.33</td>\n",
       "      <td>17.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>21.40</td>\n",
       "      <td>34.21</td>\n",
       "      <td>17.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>17.24</td>\n",
       "      <td>32.91</td>\n",
       "      <td>17.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1995</td>\n",
       "      <td>16.33</td>\n",
       "      <td>32.30</td>\n",
       "      <td>22.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996</td>\n",
       "      <td>15.55</td>\n",
       "      <td>32.71</td>\n",
       "      <td>22.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997</td>\n",
       "      <td>13.96</td>\n",
       "      <td>30.38</td>\n",
       "      <td>20.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>13.38</td>\n",
       "      <td>29.95</td>\n",
       "      <td>21.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1999</td>\n",
       "      <td>13.87</td>\n",
       "      <td>32.11</td>\n",
       "      <td>22.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>12.17</td>\n",
       "      <td>30.34</td>\n",
       "      <td>19.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001</td>\n",
       "      <td>11.94</td>\n",
       "      <td>29.64</td>\n",
       "      <td>21.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002</td>\n",
       "      <td>11.08</td>\n",
       "      <td>28.37</td>\n",
       "      <td>22.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2003</td>\n",
       "      <td>10.52</td>\n",
       "      <td>28.53</td>\n",
       "      <td>22.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004</td>\n",
       "      <td>8.17</td>\n",
       "      <td>24.89</td>\n",
       "      <td>22.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2005</td>\n",
       "      <td>7.44</td>\n",
       "      <td>23.78</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.84</td>\n",
       "      <td>27.93</td>\n",
       "      <td>23.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2007</td>\n",
       "      <td>6.74</td>\n",
       "      <td>26.45</td>\n",
       "      <td>22.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008</td>\n",
       "      <td>6.60</td>\n",
       "      <td>27.02</td>\n",
       "      <td>24.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009</td>\n",
       "      <td>5.07</td>\n",
       "      <td>25.84</td>\n",
       "      <td>24.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2010</td>\n",
       "      <td>3.49</td>\n",
       "      <td>25.47</td>\n",
       "      <td>24.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.07</td>\n",
       "      <td>28.68</td>\n",
       "      <td>23.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012</td>\n",
       "      <td>5.78</td>\n",
       "      <td>24.06</td>\n",
       "      <td>26.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013</td>\n",
       "      <td>5.77</td>\n",
       "      <td>24.82</td>\n",
       "      <td>24.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014</td>\n",
       "      <td>5.42</td>\n",
       "      <td>22.53</td>\n",
       "      <td>25.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.84</td>\n",
       "      <td>22.44</td>\n",
       "      <td>26.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016</td>\n",
       "      <td>5.58</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>5.77</td>\n",
       "      <td>22.12</td>\n",
       "      <td>26.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  avg_aqi_CO  avg_aqi_NO2  avg_aqi_O3\n",
       "0   1990       26.14        33.20       16.03\n",
       "1   1991       25.52        36.59       16.88\n",
       "2   1992       23.96        32.33       17.71\n",
       "3   1993       21.40        34.21       17.42\n",
       "4   1994       17.24        32.91       17.68\n",
       "5   1995       16.33        32.30       22.51\n",
       "6   1996       15.55        32.71       22.31\n",
       "7   1997       13.96        30.38       20.47\n",
       "8   1998       13.38        29.95       21.25\n",
       "9   1999       13.87        32.11       22.16\n",
       "10  2000       12.17        30.34       19.50\n",
       "11  2001       11.94        29.64       21.51\n",
       "12  2002       11.08        28.37       22.59\n",
       "13  2003       10.52        28.53       22.59\n",
       "14  2004        8.17        24.89       22.87\n",
       "15  2005        7.44        23.78       23.36\n",
       "16  2006        7.84        27.93       23.58\n",
       "17  2007        6.74        26.45       22.91\n",
       "18  2008        6.60        27.02       24.33\n",
       "19  2009        5.07        25.84       24.76\n",
       "20  2010        3.49        25.47       24.08\n",
       "21  2011        4.07        28.68       23.63\n",
       "22  2012        5.78        24.06       26.64\n",
       "23  2013        5.77        24.82       24.29\n",
       "24  2014        5.42        22.53       25.89\n",
       "25  2015        5.84        22.44       26.54\n",
       "26  2016        5.58        19.99       26.36\n",
       "27  2017        5.77        22.12       26.58"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green']\n",
    "labels=['CARBON MONOXIDE','NITROGEN DIOXIDE','OZONE']\n",
    "\n",
    "cols=df_final.columns.tolist()\n",
    "cols.remove('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('COMPARISON_AQI.html')\n",
    "\n",
    "##https://www.geeksforgeeks.org/python-iterate-multiple-lists-simultaneously/\n",
    "l = figure(title=\"COMPARISON OF AQI OF DIFFERENT GASES FROM 1990 TO 2017\", logo=None,width=1000, height=500)\n",
    "\n",
    "for color,label,col in zip(colors, labels, cols):\n",
    "    source = ColumnDataSource(data=dict(x=df_final['year'].tolist(), y=df_final[col].tolist())) \n",
    "    l.line(x='x',y='y',source=source, legend=label, color=color,line_width=3)\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=df_so2['year'].tolist(), y=df_so2['avg_aqi_SO2'].tolist()))\n",
    "l.line(x='x',y='y',source=source, legend='SULPHUR DIOXIDE', color=\"magenta\",line_width=5)\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=df_pm25['year'].tolist(), y=df_pm25['avg_aqi_PM25'].tolist()))\n",
    "l.line(x='x',y='y',source=source, legend='PARTICULATE MATTER', color=\"indigo\",line_width=5)\n",
    "\n",
    "l.xaxis.axis_label = 'YEAR'\n",
    "l.yaxis.axis_label = \"AVERAGE AQI\"\n",
    "l.title.text ='Comparison of AQI of CO,O3,NO2,SO2 AND PM'\n",
    "\n",
    "l.legend.location = \"top_right\"\n",
    "l.legend.click_policy=\"hide\"\n",
    "\n",
    "show(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONT GO BEYOND THIS FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>avg_aqi_CO</th>\n",
       "      <th>avg_aqi_NO2</th>\n",
       "      <th>avg_aqi_O3</th>\n",
       "      <th>avg_aqi_SO2</th>\n",
       "      <th>avg_aqi_PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>26.14</td>\n",
       "      <td>33.20</td>\n",
       "      <td>16.03</td>\n",
       "      <td>6.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>25.52</td>\n",
       "      <td>36.59</td>\n",
       "      <td>16.88</td>\n",
       "      <td>7.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>23.96</td>\n",
       "      <td>32.33</td>\n",
       "      <td>17.71</td>\n",
       "      <td>7.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>21.40</td>\n",
       "      <td>34.21</td>\n",
       "      <td>17.42</td>\n",
       "      <td>6.32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>17.24</td>\n",
       "      <td>32.91</td>\n",
       "      <td>17.68</td>\n",
       "      <td>3.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1995</td>\n",
       "      <td>16.33</td>\n",
       "      <td>32.30</td>\n",
       "      <td>22.51</td>\n",
       "      <td>5.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996</td>\n",
       "      <td>15.55</td>\n",
       "      <td>32.71</td>\n",
       "      <td>22.31</td>\n",
       "      <td>4.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997</td>\n",
       "      <td>13.96</td>\n",
       "      <td>30.38</td>\n",
       "      <td>20.47</td>\n",
       "      <td>4.81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>13.38</td>\n",
       "      <td>29.95</td>\n",
       "      <td>21.25</td>\n",
       "      <td>4.08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1999</td>\n",
       "      <td>13.87</td>\n",
       "      <td>32.11</td>\n",
       "      <td>22.16</td>\n",
       "      <td>6.04</td>\n",
       "      <td>55.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>12.17</td>\n",
       "      <td>30.34</td>\n",
       "      <td>19.50</td>\n",
       "      <td>6.05</td>\n",
       "      <td>47.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001</td>\n",
       "      <td>11.94</td>\n",
       "      <td>29.64</td>\n",
       "      <td>21.51</td>\n",
       "      <td>5.73</td>\n",
       "      <td>46.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002</td>\n",
       "      <td>11.08</td>\n",
       "      <td>28.37</td>\n",
       "      <td>22.59</td>\n",
       "      <td>5.86</td>\n",
       "      <td>51.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2003</td>\n",
       "      <td>10.52</td>\n",
       "      <td>28.53</td>\n",
       "      <td>22.59</td>\n",
       "      <td>6.06</td>\n",
       "      <td>41.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004</td>\n",
       "      <td>8.17</td>\n",
       "      <td>24.89</td>\n",
       "      <td>22.87</td>\n",
       "      <td>6.35</td>\n",
       "      <td>42.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2005</td>\n",
       "      <td>7.44</td>\n",
       "      <td>23.78</td>\n",
       "      <td>23.36</td>\n",
       "      <td>4.47</td>\n",
       "      <td>40.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.84</td>\n",
       "      <td>27.93</td>\n",
       "      <td>23.58</td>\n",
       "      <td>5.25</td>\n",
       "      <td>39.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2007</td>\n",
       "      <td>6.74</td>\n",
       "      <td>26.45</td>\n",
       "      <td>22.91</td>\n",
       "      <td>3.78</td>\n",
       "      <td>37.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008</td>\n",
       "      <td>6.60</td>\n",
       "      <td>27.02</td>\n",
       "      <td>24.33</td>\n",
       "      <td>4.03</td>\n",
       "      <td>38.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009</td>\n",
       "      <td>5.07</td>\n",
       "      <td>25.84</td>\n",
       "      <td>24.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2010</td>\n",
       "      <td>3.49</td>\n",
       "      <td>25.47</td>\n",
       "      <td>24.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.07</td>\n",
       "      <td>28.68</td>\n",
       "      <td>23.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012</td>\n",
       "      <td>5.78</td>\n",
       "      <td>24.06</td>\n",
       "      <td>26.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013</td>\n",
       "      <td>5.77</td>\n",
       "      <td>24.82</td>\n",
       "      <td>24.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014</td>\n",
       "      <td>5.42</td>\n",
       "      <td>22.53</td>\n",
       "      <td>25.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.84</td>\n",
       "      <td>22.44</td>\n",
       "      <td>26.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016</td>\n",
       "      <td>5.58</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>5.77</td>\n",
       "      <td>22.12</td>\n",
       "      <td>26.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  avg_aqi_CO  avg_aqi_NO2  avg_aqi_O3  avg_aqi_SO2  avg_aqi_PM25\n",
       "0   1990       26.14        33.20       16.03         6.43           NaN\n",
       "1   1991       25.52        36.59       16.88         7.33           NaN\n",
       "2   1992       23.96        32.33       17.71         7.45           NaN\n",
       "3   1993       21.40        34.21       17.42         6.32           NaN\n",
       "4   1994       17.24        32.91       17.68         3.52           NaN\n",
       "5   1995       16.33        32.30       22.51         5.59           NaN\n",
       "6   1996       15.55        32.71       22.31         4.88           NaN\n",
       "7   1997       13.96        30.38       20.47         4.81           NaN\n",
       "8   1998       13.38        29.95       21.25         4.08           NaN\n",
       "9   1999       13.87        32.11       22.16         6.04         55.62\n",
       "10  2000       12.17        30.34       19.50         6.05         47.93\n",
       "11  2001       11.94        29.64       21.51         5.73         46.36\n",
       "12  2002       11.08        28.37       22.59         5.86         51.68\n",
       "13  2003       10.52        28.53       22.59         6.06         41.77\n",
       "14  2004        8.17        24.89       22.87         6.35         42.45\n",
       "15  2005        7.44        23.78       23.36         4.47         40.50\n",
       "16  2006        7.84        27.93       23.58         5.25         39.53\n",
       "17  2007        6.74        26.45       22.91         3.78         37.66\n",
       "18  2008        6.60        27.02       24.33         4.03         38.51\n",
       "19  2009        5.07        25.84       24.76          NaN         44.13\n",
       "20  2010        3.49        25.47       24.08          NaN         40.60\n",
       "21  2011        4.07        28.68       23.63          NaN         36.68\n",
       "22  2012        5.78        24.06       26.64          NaN         32.39\n",
       "23  2013        5.77        24.82       24.29          NaN         38.77\n",
       "24  2014        5.42        22.53       25.89          NaN         30.77\n",
       "25  2015        5.84        22.44       26.54          NaN         29.99\n",
       "26  2016        5.58        19.99       26.36          NaN         31.10\n",
       "27  2017        5.77        22.12       26.58          NaN         36.82"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(df_final, df_so2, how='left', on='year')\n",
    "df_merged = pd.merge(result, df_pm25, how='left', on='year')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values in so2 and pm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp=Imputer(missing_values='NaN',strategy='mean')\n",
    "\n",
    "## replace missing values in aqi and method code with mean\n",
    "df_merged[\"avg_aqi_SO2\"]=imp.fit_transform(df_merged[[\"avg_aqi_SO2\"]]).ravel()\n",
    "df_merged[\"avg_aqi_PM25\"]=imp.fit_transform(df_merged[[\"avg_aqi_PM25\"]]).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SF INCIDENTS DATABASE INCIDENTS PER YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sf=\"\"\" SELECT EXTRACT(YEAR FROM timestamp) as year,count(distinct unique_key) as no_of_incidents\n",
    "FROM `bigquery-public-data.san_francisco.sfpd_incidents`\n",
    "group by year\n",
    "order by year asc \n",
    "\"\"\"\n",
    "\n",
    "df_sf_incidents = bq_assistant.query_to_pandas(query_sf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_incidents.year = df_sf_incidents.year.astype(str)\n",
    "df_combined = pd.merge(df_merged, df_sf_incidents, how='left', on='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>avg_aqi_CO</th>\n",
       "      <th>avg_aqi_NO2</th>\n",
       "      <th>avg_aqi_O3</th>\n",
       "      <th>avg_aqi_SO2</th>\n",
       "      <th>avg_aqi_PM25</th>\n",
       "      <th>no_of_incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>26.14</td>\n",
       "      <td>33.20</td>\n",
       "      <td>16.03</td>\n",
       "      <td>6.430000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>25.52</td>\n",
       "      <td>36.59</td>\n",
       "      <td>16.88</td>\n",
       "      <td>7.330000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>23.96</td>\n",
       "      <td>32.33</td>\n",
       "      <td>17.71</td>\n",
       "      <td>7.450000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>21.40</td>\n",
       "      <td>34.21</td>\n",
       "      <td>17.42</td>\n",
       "      <td>6.320000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>17.24</td>\n",
       "      <td>32.91</td>\n",
       "      <td>17.68</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1995</td>\n",
       "      <td>16.33</td>\n",
       "      <td>32.30</td>\n",
       "      <td>22.51</td>\n",
       "      <td>5.590000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996</td>\n",
       "      <td>15.55</td>\n",
       "      <td>32.71</td>\n",
       "      <td>22.31</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997</td>\n",
       "      <td>13.96</td>\n",
       "      <td>30.38</td>\n",
       "      <td>20.47</td>\n",
       "      <td>4.810000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>13.38</td>\n",
       "      <td>29.95</td>\n",
       "      <td>21.25</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>40.171579</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1999</td>\n",
       "      <td>13.87</td>\n",
       "      <td>32.11</td>\n",
       "      <td>22.16</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>55.620000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>12.17</td>\n",
       "      <td>30.34</td>\n",
       "      <td>19.50</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>47.930000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001</td>\n",
       "      <td>11.94</td>\n",
       "      <td>29.64</td>\n",
       "      <td>21.51</td>\n",
       "      <td>5.730000</td>\n",
       "      <td>46.360000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002</td>\n",
       "      <td>11.08</td>\n",
       "      <td>28.37</td>\n",
       "      <td>22.59</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>51.680000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2003</td>\n",
       "      <td>10.52</td>\n",
       "      <td>28.53</td>\n",
       "      <td>22.59</td>\n",
       "      <td>6.060000</td>\n",
       "      <td>41.770000</td>\n",
       "      <td>118892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004</td>\n",
       "      <td>8.17</td>\n",
       "      <td>24.89</td>\n",
       "      <td>22.87</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>42.450000</td>\n",
       "      <td>117238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2005</td>\n",
       "      <td>7.44</td>\n",
       "      <td>23.78</td>\n",
       "      <td>23.36</td>\n",
       "      <td>4.470000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>116357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.84</td>\n",
       "      <td>27.93</td>\n",
       "      <td>23.58</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>39.530000</td>\n",
       "      <td>116779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2007</td>\n",
       "      <td>6.74</td>\n",
       "      <td>26.45</td>\n",
       "      <td>22.91</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>37.660000</td>\n",
       "      <td>112975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008</td>\n",
       "      <td>6.60</td>\n",
       "      <td>27.02</td>\n",
       "      <td>24.33</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>38.510000</td>\n",
       "      <td>115671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009</td>\n",
       "      <td>5.07</td>\n",
       "      <td>25.84</td>\n",
       "      <td>24.76</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>44.130000</td>\n",
       "      <td>109196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2010</td>\n",
       "      <td>3.49</td>\n",
       "      <td>25.47</td>\n",
       "      <td>24.08</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>102109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.07</td>\n",
       "      <td>28.68</td>\n",
       "      <td>23.63</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>36.680000</td>\n",
       "      <td>101486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012</td>\n",
       "      <td>5.78</td>\n",
       "      <td>24.06</td>\n",
       "      <td>26.64</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>32.390000</td>\n",
       "      <td>108779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013</td>\n",
       "      <td>5.77</td>\n",
       "      <td>24.82</td>\n",
       "      <td>24.29</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>38.770000</td>\n",
       "      <td>115190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014</td>\n",
       "      <td>5.42</td>\n",
       "      <td>22.53</td>\n",
       "      <td>25.89</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>116397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.84</td>\n",
       "      <td>22.44</td>\n",
       "      <td>26.54</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>29.990000</td>\n",
       "      <td>122162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016</td>\n",
       "      <td>5.58</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.36</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>116924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>5.77</td>\n",
       "      <td>22.12</td>\n",
       "      <td>26.58</td>\n",
       "      <td>5.475263</td>\n",
       "      <td>36.820000</td>\n",
       "      <td>120620.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  avg_aqi_CO  avg_aqi_NO2  avg_aqi_O3  avg_aqi_SO2  avg_aqi_PM25  \\\n",
       "0   1990       26.14        33.20       16.03     6.430000     40.171579   \n",
       "1   1991       25.52        36.59       16.88     7.330000     40.171579   \n",
       "2   1992       23.96        32.33       17.71     7.450000     40.171579   \n",
       "3   1993       21.40        34.21       17.42     6.320000     40.171579   \n",
       "4   1994       17.24        32.91       17.68     3.520000     40.171579   \n",
       "5   1995       16.33        32.30       22.51     5.590000     40.171579   \n",
       "6   1996       15.55        32.71       22.31     4.880000     40.171579   \n",
       "7   1997       13.96        30.38       20.47     4.810000     40.171579   \n",
       "8   1998       13.38        29.95       21.25     4.080000     40.171579   \n",
       "9   1999       13.87        32.11       22.16     6.040000     55.620000   \n",
       "10  2000       12.17        30.34       19.50     6.050000     47.930000   \n",
       "11  2001       11.94        29.64       21.51     5.730000     46.360000   \n",
       "12  2002       11.08        28.37       22.59     5.860000     51.680000   \n",
       "13  2003       10.52        28.53       22.59     6.060000     41.770000   \n",
       "14  2004        8.17        24.89       22.87     6.350000     42.450000   \n",
       "15  2005        7.44        23.78       23.36     4.470000     40.500000   \n",
       "16  2006        7.84        27.93       23.58     5.250000     39.530000   \n",
       "17  2007        6.74        26.45       22.91     3.780000     37.660000   \n",
       "18  2008        6.60        27.02       24.33     4.030000     38.510000   \n",
       "19  2009        5.07        25.84       24.76     5.475263     44.130000   \n",
       "20  2010        3.49        25.47       24.08     5.475263     40.600000   \n",
       "21  2011        4.07        28.68       23.63     5.475263     36.680000   \n",
       "22  2012        5.78        24.06       26.64     5.475263     32.390000   \n",
       "23  2013        5.77        24.82       24.29     5.475263     38.770000   \n",
       "24  2014        5.42        22.53       25.89     5.475263     30.770000   \n",
       "25  2015        5.84        22.44       26.54     5.475263     29.990000   \n",
       "26  2016        5.58        19.99       26.36     5.475263     31.100000   \n",
       "27  2017        5.77        22.12       26.58     5.475263     36.820000   \n",
       "\n",
       "    no_of_incidents  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "5               NaN  \n",
       "6               NaN  \n",
       "7               NaN  \n",
       "8               NaN  \n",
       "9               NaN  \n",
       "10              NaN  \n",
       "11              NaN  \n",
       "12              NaN  \n",
       "13         118892.0  \n",
       "14         117238.0  \n",
       "15         116357.0  \n",
       "16         116779.0  \n",
       "17         112975.0  \n",
       "18         115671.0  \n",
       "19         109196.0  \n",
       "20         102109.0  \n",
       "21         101486.0  \n",
       "22         108779.0  \n",
       "23         115190.0  \n",
       "24         116397.0  \n",
       "25         122162.0  \n",
       "26         116924.0  \n",
       "27         120620.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"no_of_incidents\"]=imp.fit_transform(df_combined[[\"no_of_incidents\"]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                object\n",
       "avg_aqi_CO         float64\n",
       "avg_aqi_NO2        float64\n",
       "avg_aqi_O3         float64\n",
       "avg_aqi_SO2        float64\n",
       "avg_aqi_PM25       float64\n",
       "no_of_incidents    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Serialize df to a pickle object\n",
    "## Skip every line above\n",
    "import pickle\n",
    "\n",
    "picle_out=open('df_merged_frame.pickle','wb')\n",
    "pickle.dump(df_combined,picle_out)\n",
    "picle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deserialize the pickle object to get back the data frame\n",
    "import pickle\n",
    "\n",
    "picle_in=open('df_merged_frame.pickle','rb')\n",
    "df=pickle.load(picle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deserialize the pickle object to get back the data frame\n",
    "picle_in=open('population/dataframe.pickle','rb')\n",
    "df_pop_per_yr=pickle.load(picle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove trailing zeroes\n",
    "df_pop_per_yr['year'] = df_pop_per_yr['year'].astype(str).replace('\\.0', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.merge(df, df_pop_per_yr, how='inner', on='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['Incidents_per_population']=df_comb['no_of_incidents']/df_comb['Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_per_yr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.drop(['no_of_incidents','Population'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Optional Standard Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# df[['avg_aqi_CO', 'avg_aqi_NO2','avg_aqi_O3','avg_aqi_SO2','avg_aqi_PM25']] = StandardScaler().fit_transform(df[['avg_aqi_CO', 'avg_aqi_NO2','avg_aqi_O3','avg_aqi_SO2','avg_aqi_PM25']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional MinMax Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df[['avg_aqi_CO', 'avg_aqi_NO2','avg_aqi_O3','avg_aqi_SO2','avg_aqi_PM25']] = MinMaxScaler().fit_transform(df[['avg_aqi_CO', 'avg_aqi_NO2','avg_aqi_O3','avg_aqi_SO2','avg_aqi_PM25']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra=pd.read_excel('population/SFCRIMERATE.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra[['Median age', 'Average household size', 'Average family size',\n",
    "       'Median value owner occupied unit', 'Median household income',\n",
    "       'Median family income', 'Per capita income', 'Crime Index']]=imp.fit_transform(df_extra[['Median age', 'Average household size', 'Average family size',\n",
    "       'Median value owner occupied unit', 'Median household income',\n",
    "       'Median family income', 'Per capita income', 'Crime Index']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra.Year=df_extra.Year.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra[['Median age', 'Average household size', 'Average family size',\n",
    "       'Median value owner occupied unit', 'Median household income',\n",
    "       'Median family income', 'Per capita income', 'Crime Index']] = MinMaxScaler().fit_transform(df_extra[['Median age', 'Average household size', 'Average family size',\n",
    "       'Median value owner occupied unit', 'Median household income',\n",
    "       'Median family income', 'Per capita income', 'Crime Index']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra[['Median age', 'Average household size', 'Average family size',\n",
    "       'Median value owner occupied unit', 'Median household income',\n",
    "       'Median family income', 'Per capita income', 'Crime Index']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[['avg_aqi_CO', 'avg_aqi_NO2', 'avg_aqi_O3', 'avg_aqi_SO2',\n",
    "       'avg_aqi_PM25','Incidents_per_population']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final=pd.merge(df, df_extra, how='inner', left_on='year',right_on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final.drop(['year'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['avg_aqi_CO', 'avg_aqi_NO2', 'avg_aqi_O3',\n",
    "       'avg_aqi_PM25', 'Median age',\n",
    "       'Average household size', 'Average family size',\n",
    "       'Median value owner occupied unit', 'Median household income',\n",
    "       'Median family income', 'Per capita income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataframe_final[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataframe_final['Crime Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most important features relative to target\n",
    "print(\"Find most important features relative to target\")\n",
    "corr = dataframe_final.corr()\n",
    "corr.sort_values(['Crime Index'], ascending = False, inplace = True)\n",
    "print(corr['Crime Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,Y)\n",
    "\n",
    "predictions = lm.predict(X)\n",
    "print('Accuracy of model=',lm.score(X,Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "                               \n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods=['Linear_Regression']\n",
    "vals=[]\n",
    "## Vals contains rmse for test set\n",
    "vals.append(np.sqrt(metrics.mean_squared_error(y_test, predictions))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The line / model\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## R2 score Evaluation\n",
    "y_train_pred=model.predict(X_train)\n",
    "y_test_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"r2 train: %.3f, test : %.3f\" %(r2_score(y_train,y_train_pred),r2_score(y_test,y_test_pred) ))\n",
    "\n",
    "print('Rmse VAlue is:')\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance in Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(model.coef_, index = X_train.columns)\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Linear Regression Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=324)\n",
    "\n",
    "regressor = DecisionTreeRegressor(max_depth=20)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "## R2 score Evaluation\n",
    "y_train_pred=regressor.predict(X_train)\n",
    "y_test_pred=regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"r2 train: %.3f, test : %.3f\" %(r2_score(y_train,y_train_pred),r2_score(y_test,y_test_pred) ))\n",
    "\n",
    "\n",
    "mods.append('Decision_Tree_Regressor')\n",
    "vals.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(regressor.feature_importances_, index = X_train.columns)\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Decision Tree Regression Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "\n",
    "forest=RandomForestRegressor(n_estimators=1000,criterion='mse',random_state=1,n_jobs=-1)\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "## R2 score Evaluation\n",
    "y_train_pred=forest.predict(X_train)\n",
    "y_test_pred=forest.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"r2 train: %.3f, test : %.3f\" %(r2_score(y_train,y_train_pred),r2_score(y_test,y_test_pred) ))\n",
    "\n",
    "mods.append('Random Forest Regressor')\n",
    "vals.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(forest.feature_importances_, index = X_train.columns)\n",
    "imp_coefs = pd.concat([coefs.sort_values().head(10),\n",
    "                     coefs.sort_values().tail(10)])\n",
    "imp_coefs.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Random Forest Regression Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV,Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def rmse_cv_train(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "def rmse_cv_test(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_test, y_test, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = Ridge()\n",
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\n",
    "cv_ridge = [rmse_cv_test(Ridge(alpha = alpha)).mean() \n",
    "            for alpha in alphas]\n",
    "\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ridge.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.append('Ridge Regressor')\n",
    "vals.append(cv_ridge.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model_ridge=RidgeCV(alphas=alphas)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "rmse_cv_test(model_ridge).mean()\n",
    "\n",
    "coef = pd.Series(model_ridge.coef_, index = X_train.columns)\n",
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Ridge Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = LassoCV()\n",
    "alphas = [1, 0.1, 0.001, 0.0005]\n",
    "cv_lasso = [rmse_cv_test(Lasso(alpha = alpha)).mean() \n",
    "            for alpha in alphas]\n",
    "\n",
    "cv_lasso = pd.Series(cv_lasso, index = alphas)\n",
    "cv_lasso.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lasso = Lasso(alpha=cv_lasso.idxmin)\n",
    "# model_lasso.fit(X_train, y_train)\n",
    "# # rmse_cv_test(model_lasso).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mods.append('Lasso Regressor')\n",
    "vals.append(rmse_cv_train(model_lasso).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model_lasso=RidgeCV(alphas=alphas)\n",
    "model_lasso.fit(X_train, y_train)\n",
    "rmse_cv_test(model_lasso).mean()\n",
    "\n",
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)\n",
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ser_df=pd.DataFrame({'Model': mods, 'Accuracy_Value': vals})\n",
    "\n",
    "source = ColumnDataSource(ser_df)\n",
    "\n",
    "p = figure(x_range=mods, plot_width=900, plot_height=500)\n",
    "color_map = factor_cmap(field_name='Model', palette=Spectral6, factors=mods)\n",
    "p.vbar(x='Model', top='Accuracy_Value', source=source, width=0.70, color=color_map)\n",
    "\n",
    "p.title.text ='Comparison of Models'\n",
    "p.xaxis.axis_label = 'Model Types'\n",
    "p.yaxis.axis_label = \"RMSE value of different models On Test Set\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore Everything below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding an xgboost model:¶\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # import xgboost as xgb\n",
    "\n",
    "# # dtrain = xgb.DMatrix(X, label = Y)\n",
    "# # dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# # params = {\"max_depth\":2, \"eta\":0.1}\n",
    "# # model = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)\n",
    "# # model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()\n",
    "\n",
    "\n",
    "# # model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1) #the params were tuned using xgb.cv\n",
    "# # model_xgb.fit(X, Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Reference https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "\n",
    "# from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "# from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "# from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import xgboost as xgb\n",
    "\n",
    "# #Validation function\n",
    "# n_folds = 5\n",
    "\n",
    "# def rmsle_cv(model):\n",
    "#     kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n",
    "#     rmse= np.sqrt(-cross_val_score(model, X.values, Y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "#     return(rmse)\n",
    "\n",
    "# # LASSO Regression\n",
    "\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "# # Elastic Net Regression\n",
    "\n",
    "# ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "\n",
    "# # Kernel Ridge Regression\n",
    "\n",
    "# KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "\n",
    "# # Gradient Boosting Regression\n",
    "\n",
    "# GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "#                                    max_depth=4, max_features='sqrt',\n",
    "#                                    min_samples_leaf=15, min_samples_split=10, \n",
    "#                                    loss='huber', random_state =5)\n",
    "\n",
    "# # XGBoost\n",
    "\n",
    "# model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "#                              learning_rate=0.05, max_depth=3, \n",
    "#                              min_child_weight=1.7817, n_estimators=2200,\n",
    "#                              reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "#                              subsample=0.5213, silent=1,\n",
    "#                              random_state =7, nthread = -1)\n",
    "\n",
    "# # Model Evaluation Scores\n",
    "\n",
    "# score = rmsle_cv(lasso)\n",
    "# print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "# score = rmsle_cv(ENet)\n",
    "# print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "# score = rmsle_cv(KRR)\n",
    "# print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "# score = rmsle_cv(GBoost)\n",
    "# print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "# score = rmsle_cv(model_xgb)\n",
    "# print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "# Useless Stuff after this\n",
    "\n",
    "# columns = df.columns\n",
    "# percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "# missing_value_df = pd.DataFrame({'column_name': columns,\n",
    "#                                  'percent_missing': percent_missing})\n",
    "\n",
    "# missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "\n",
    "\n",
    "# # Prints R2 and RMSE scores\n",
    "# def get_score(prediction, lables):    \n",
    "#     print('R2: {}'.format(r2_score(prediction, lables)))\n",
    "#     print('RMSE: {}'.format(np.sqrt(mean_squared_error(prediction, lables))))\n",
    "\n",
    "# # Shows scores for train and validation sets    \n",
    "# def train_test(estimator, x_trn, x_tst, y_trn, y_tst):\n",
    "#     prediction_train = estimator.predict(x_trn)\n",
    "#     # Printing estimator\n",
    "#     print(estimator)\n",
    "#     # Printing train scores\n",
    "#     get_score(prediction_train, y_trn)\n",
    "#     prediction_test = estimator.predict(x_tst)\n",
    "#     # Printing test scores\n",
    "#     print(\"Test\")\n",
    "#     get_score(prediction_test, y_tst)\n",
    "\n",
    "# # ### Splitting\n",
    "# # x_train, x_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.1, random_state=200)\n",
    "# # x_train_st, x_test_st, y_train_st, y_test_st = train_test_split(train_features_st, train_labels, test_size=0.1, random_state=200)\n",
    "\n",
    "# ENSTest = linear_model.ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], l1_ratio=[.01, .1, .5, .9, .99], max_iter=5000).fit(X_train, y_train)\n",
    "# train_test(ENSTest,X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Average R2 score and standart deviation of 5-fold cross-validation\n",
    "# scores = cross_val_score(ENSTest, X, Y, cv=5)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# from sklearn import ensemble\n",
    "# GBest = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features='sqrt',\n",
    "#                                                min_samples_leaf=15, min_samples_split=10, loss='huber').fit(X_train, y_train)\n",
    "# train_test(GBest, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Average R2 score and standart deviation of 5-fold cross-validation\n",
    "# scores = cross_val_score(GBest,  X, Y, cv=5)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

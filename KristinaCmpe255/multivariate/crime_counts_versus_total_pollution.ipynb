{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes annoying deprecation warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from bq_helper import BigQueryHelper #third party library to translate google query data to dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, './../utils/')\n",
    "\n",
    "# custom files \n",
    "import random_forest_regressor as rfr\n",
    "import utilities as util\n",
    "import validation as cv\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with open('../../key.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "#add your own key here \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']= content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_QUERY = \"\"\"\n",
    "        SELECT\n",
    "            avg(CO_daily.arithmetic_mean) as COam,\n",
    "            cast(EXTRACT(YEAR FROM CO_daily.date_local)*10000 +\n",
    "            EXTRACT(MONTH FROM CO_daily.date_local)*100 + \n",
    "            EXTRACT(DAY FROM CO_daily.date_local) as string) as COdate,\n",
    "            avg(PPM_daily.arithmetic_mean) as PPMam,\n",
    "            EXTRACT(YEAR FROM PPM_daily.date_local)*10000 +\n",
    "            EXTRACT(MONTH FROM PPM_daily.date_local)*100 + \n",
    "            EXTRACT(DAY FROM PPM_daily.date_local) as PPMdate,\n",
    "            avg(SO2_daily.arithmetic_mean) as SO2am,\n",
    "            EXTRACT(YEAR FROM SO2_daily.date_local)*10000 +\n",
    "            EXTRACT(MONTH FROM SO2_daily.date_local)*100 + \n",
    "            EXTRACT(DAY FROM SO2_daily.date_local) as SO2date,\n",
    "            avg(NO2_daily.arithmetic_mean) as NO2am,\n",
    "            EXTRACT(YEAR FROM NO2_daily.date_local)*10000 +\n",
    "            EXTRACT(MONTH FROM NO2_daily.date_local)*100 + \n",
    "            EXTRACT(DAY FROM NO2_daily.date_local) as NO2date\n",
    "        FROM\n",
    "          `bigquery-public-data.epa_historical_air_quality.co_daily_summary` as CO_daily\n",
    "          INNER JOIN `bigquery-public-data.epa_historical_air_quality.pm25_frm_daily_summary` as PPM_daily ON CO_daily.date_local = PPM_daily.date_local\n",
    "          INNER JOIN `bigquery-public-data.epa_historical_air_quality.so2_daily_summary` as SO2_daily ON CO_daily.date_local = SO2_daily.date_local\n",
    "          INNER JOIN `bigquery-public-data.epa_historical_air_quality.no2_daily_summary` as NO2_daily ON CO_daily.date_local = NO2_daily.date_local\n",
    "        WHERE CO_daily.state_name =\"California\" AND CO_daily.city_name=\"San Francisco\" AND\n",
    "        PPM_daily.state_name =\"California\" AND PPM_daily.city_name=\"San Francisco\" AND\n",
    "        SO2_daily.state_name =\"California\" AND SO2_daily.city_name=\"San Francisco\" AND\n",
    "        NO2_daily.state_name =\"California\" AND NO2_daily.city_name=\"San Francisco\"\n",
    "        GROUP BY COdate, PPMdate, SO2date, NO2date\n",
    "        ORDER BY COdate DESC\n",
    "        \"\"\"\n",
    "bq_assistant = BigQueryHelper(\"bigquery-public-data\", \"epa_historical_air_quality\")\n",
    "df_POLLUTION = bq_assistant.query_to_pandas(EPA_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COam</th>\n",
       "      <th>COdate</th>\n",
       "      <th>PPMam</th>\n",
       "      <th>PPMdate</th>\n",
       "      <th>SO2am</th>\n",
       "      <th>SO2date</th>\n",
       "      <th>NO2am</th>\n",
       "      <th>NO2date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.410598</td>\n",
       "      <td>20081220</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20081220</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>20081220</td>\n",
       "      <td>19.450000</td>\n",
       "      <td>20081220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.415399</td>\n",
       "      <td>20081217</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20081217</td>\n",
       "      <td>1.669481</td>\n",
       "      <td>20081217</td>\n",
       "      <td>24.238095</td>\n",
       "      <td>20081217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327898</td>\n",
       "      <td>20081214</td>\n",
       "      <td>4.7</td>\n",
       "      <td>20081214</td>\n",
       "      <td>0.227922</td>\n",
       "      <td>20081214</td>\n",
       "      <td>16.608696</td>\n",
       "      <td>20081214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.773279</td>\n",
       "      <td>20081211</td>\n",
       "      <td>22.1</td>\n",
       "      <td>20081211</td>\n",
       "      <td>2.962987</td>\n",
       "      <td>20081211</td>\n",
       "      <td>29.952381</td>\n",
       "      <td>20081211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.618206</td>\n",
       "      <td>20081208</td>\n",
       "      <td>18.6</td>\n",
       "      <td>20081208</td>\n",
       "      <td>1.397403</td>\n",
       "      <td>20081208</td>\n",
       "      <td>22.863636</td>\n",
       "      <td>20081208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       COam    COdate  PPMam   PPMdate     SO2am   SO2date      NO2am  \\\n",
       "0  0.410598  20081220    7.0  20081220  2.500000  20081220  19.450000   \n",
       "1  0.415399  20081217    6.5  20081217  1.669481  20081217  24.238095   \n",
       "2  0.327898  20081214    4.7  20081214  0.227922  20081214  16.608696   \n",
       "3  0.773279  20081211   22.1  20081211  2.962987  20081211  29.952381   \n",
       "4  0.618206  20081208   18.6  20081208  1.397403  20081208  22.863636   \n",
       "\n",
       "    NO2date  \n",
       "0  20081220  \n",
       "1  20081217  \n",
       "2  20081214  \n",
       "3  20081211  \n",
       "4  20081208  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_POLLUTION.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_CRIME_QUERY = \"\"\"\n",
    "        SELECT\n",
    "            COUNT( DISTINCT unique_key) as count,\n",
    "            cast(EXTRACT(YEAR FROM SFCrimeData.timestamp)*10000 +\n",
    "            EXTRACT(MONTH FROM SFCrimeData.timestamp)*100 + \n",
    "            EXTRACT(DAY FROM SFCrimeData.timestamp) as string) as date\n",
    "        FROM\n",
    "          `bigquery-public-data.san_francisco_sfpd_incidents.sfpd_incidents` AS SFCrimeData\n",
    "        WHERE category != \"NON-CRIMINAL\" AND category != \"RECOVERED VEHICLE\"\n",
    "        GROUP BY date\n",
    "        ORDER BY date DESC\n",
    "        \"\"\"\n",
    "\n",
    "bq_assistant_SF_crime = BigQueryHelper(\"bigquery-public-data\", \"san_francisco_sfpd_incidents.sfpd_incidents\")\n",
    "df_SF_crime = bq_assistant_SF_crime.query_to_pandas(SF_CRIME_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>757638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>750133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>748846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>751431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>758348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>767067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>774347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>805770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>816294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>830406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>853258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>866320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>876103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>884363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>884363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year     pop\n",
       "0   2003  757638\n",
       "1   2004  750133\n",
       "2   2005  748846\n",
       "3   2006  751431\n",
       "4   2007  758348\n",
       "5   2008  767067\n",
       "6   2009  774347\n",
       "7   2010  805770\n",
       "8   2011  816294\n",
       "9   2012  830406\n",
       "10  2013  841270\n",
       "11  2014  853258\n",
       "12  2015  866320\n",
       "13  2016  876103\n",
       "14  2017  884363\n",
       "15  2018  884363"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SF_census = pd.read_csv('../../data/censuspopulationsf.tsv', sep='\\t', header=None)\n",
    "df_SF_census.columns = ['year', 'pop']\n",
    "df_SF_census.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>COam</th>\n",
       "      <th>PPMam</th>\n",
       "      <th>SO2am</th>\n",
       "      <th>NO2am</th>\n",
       "      <th>count</th>\n",
       "      <th>per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>20081220</td>\n",
       "      <td>0.410598</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>19.450000</td>\n",
       "      <td>329</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>20081217</td>\n",
       "      <td>0.415399</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.669481</td>\n",
       "      <td>24.238095</td>\n",
       "      <td>266</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>20081214</td>\n",
       "      <td>0.327898</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.227922</td>\n",
       "      <td>16.608696</td>\n",
       "      <td>202</td>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>20081211</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>22.1</td>\n",
       "      <td>2.962987</td>\n",
       "      <td>29.952381</td>\n",
       "      <td>277</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>20081208</td>\n",
       "      <td>0.618206</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.397403</td>\n",
       "      <td>22.863636</td>\n",
       "      <td>271</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      COam  PPMam     SO2am      NO2am  count  per_capita\n",
       "3432  20081220  0.410598    7.0  2.500000  19.450000    329    0.000429\n",
       "3435  20081217  0.415399    6.5  1.669481  24.238095    266    0.000347\n",
       "3438  20081214  0.327898    4.7  0.227922  16.608696    202    0.000263\n",
       "3441  20081211  0.773279   22.1  2.962987  29.952381    277    0.000361\n",
       "3444  20081208  0.618206   18.6  1.397403  22.863636    271    0.000353"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make column for counts per capita\n",
    "util.per_capita(df_SF_crime, df_SF_census)\n",
    "# merge CO and Crime data\n",
    "df_POLLUTION.rename(columns={'COdate': 'date'}, inplace=True)\n",
    "df_merged = util.merge_data(df_POLLUTION[['date', 'COam', 'PPMam', 'SO2am', 'NO2am']], df_SF_crime)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristina/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=250, min_samples_split=8, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=250, min_samples_split=8, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=250, min_samples_split=8, max_depth=50, bootstrap=True \n",
      "[CV] n_estimators=275, min_samples_split=4, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=250, min_samples_split=8, max_depth=50, bootstrap=True, total=   0.3s\n",
      "[CV] n_estimators=275, min_samples_split=4, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=250, min_samples_split=8, max_depth=50, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=275, min_samples_split=4, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=250, min_samples_split=8, max_depth=50, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=250, min_samples_split=2, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=275, min_samples_split=4, max_depth=80, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=250, min_samples_split=2, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=250, min_samples_split=2, max_depth=10, bootstrap=False, total=   0.3s\n",
      "[CV] n_estimators=250, min_samples_split=2, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=275, min_samples_split=4, max_depth=80, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=175, min_samples_split=10, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=275, min_samples_split=4, max_depth=80, bootstrap=True, total=   0.5s\n",
      "[CV] n_estimators=175, min_samples_split=10, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=250, min_samples_split=2, max_depth=10, bootstrap=False, total=   0.4s\n",
      "[CV] n_estimators=175, min_samples_split=10, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=250, min_samples_split=2, max_depth=10, bootstrap=False, total=   0.3s\n",
      "[CV] n_estimators=275, min_samples_split=10, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=175, min_samples_split=10, max_depth=70, bootstrap=True, total=   0.3s\n",
      "[CV] n_estimators=275, min_samples_split=10, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=175, min_samples_split=10, max_depth=70, bootstrap=True, total=   0.2s\n",
      "[CV] n_estimators=275, min_samples_split=10, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=175, min_samples_split=10, max_depth=70, bootstrap=True, total=   0.3s\n",
      "[CV] n_estimators=200, min_samples_split=10, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=10, max_depth=10, bootstrap=False, total=   0.3s\n",
      "[CV]  n_estimators=275, min_samples_split=10, max_depth=20, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=200, min_samples_split=10, max_depth=10, bootstrap=False \n",
      "[CV] n_estimators=200, min_samples_split=10, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=275, min_samples_split=10, max_depth=20, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=125, min_samples_split=4, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=275, min_samples_split=10, max_depth=20, bootstrap=True, total=   0.5s\n",
      "[CV] n_estimators=125, min_samples_split=4, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=10, max_depth=10, bootstrap=False, total=   0.3s\n",
      "[CV] n_estimators=125, min_samples_split=4, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=125, min_samples_split=4, max_depth=70, bootstrap=True, total=   0.2s\n",
      "[CV] n_estimators=300, min_samples_split=4, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=125, min_samples_split=4, max_depth=70, bootstrap=True, total=   0.2s\n",
      "[CV] n_estimators=300, min_samples_split=4, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=10, max_depth=10, bootstrap=False, total=   0.4s\n",
      "[CV] n_estimators=300, min_samples_split=4, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=125, min_samples_split=4, max_depth=70, bootstrap=True, total=   0.2s\n",
      "[CV] n_estimators=225, min_samples_split=4, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=300, min_samples_split=4, max_depth=30, bootstrap=True, total=   0.5s\n",
      "[CV] n_estimators=225, min_samples_split=4, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=225, min_samples_split=4, max_depth=20, bootstrap=True, total=   0.4s\n",
      "[CV] n_estimators=225, min_samples_split=4, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=300, min_samples_split=4, max_depth=30, bootstrap=True, total=   0.5s\n",
      "[CV] n_estimators=150, min_samples_split=4, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=300, min_samples_split=4, max_depth=30, bootstrap=True, total=   0.6s\n",
      "[CV] n_estimators=150, min_samples_split=4, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=150, min_samples_split=4, max_depth=10, bootstrap=False, total=   0.2s\n",
      "[CV] n_estimators=150, min_samples_split=4, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=150, min_samples_split=4, max_depth=10, bootstrap=False, total=   0.2s\n",
      "[CV]  n_estimators=225, min_samples_split=4, max_depth=20, bootstrap=True, total=   0.4s\n",
      "[CV]  n_estimators=225, min_samples_split=4, max_depth=20, bootstrap=True, total=   0.4s\n",
      "[CV]  n_estimators=150, min_samples_split=4, max_depth=10, bootstrap=False, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=70,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=4,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=125, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find optimum regressor\n",
    "regr = rfr.find_regressor(df_merged[['date', 'COam', 'PPMam', 'SO2am', 'NO2am']].as_matrix(), df_merged['per_capita'].values)\n",
    "regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./../utils/random_forest_regressor.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  regr.fit(X_train.as_matrix(), y_train)\n",
      "./../utils/random_forest_regressor.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  return regr.predict(X_test.as_matrix())\n"
     ]
    }
   ],
   "source": [
    "# split dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_merged[['date', 'COam', 'PPMam', 'SO2am', 'NO2am']], df_merged['per_capita'].values, test_size=0.33, random_state=42)\n",
    "# make predictions based on optimum regressor\n",
    "y_pred = rfr.fit_and_predict(regr, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7580211083441344e-09"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.MSE(y_test, y_pred)\n",
    "# leave one out cross validation \n",
    "# loo = cross_validation.LeaveOneOut(len(df_merged['per_capita'].values))\n",
    "# loo_score = cv.Cross_Validation(loo, regr, df_merged[['date','am']].as_matrix(), df_merged['per_capita'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation using time series split (additive): 2.104379467336409e-09 \n"
     ]
    }
   ],
   "source": [
    "# 10 fold tss cross validation\n",
    "tss_score = cv.Cross_Validation(df_merged[['date', 'COam', 'PPMam', 'SO2am', 'NO2am']], df_merged['per_capita'], regr, 10)\n",
    "print('10-fold cross validation using time series split (additive): {} '.format(tss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COam</th>\n",
       "      <th>PPMam</th>\n",
       "      <th>SO2am</th>\n",
       "      <th>NO2am</th>\n",
       "      <th>count</th>\n",
       "      <th>per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COam</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509747</td>\n",
       "      <td>0.619965</td>\n",
       "      <td>0.802885</td>\n",
       "      <td>0.140665</td>\n",
       "      <td>0.145777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPMam</th>\n",
       "      <td>0.509747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608483</td>\n",
       "      <td>0.589155</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.036684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO2am</th>\n",
       "      <td>0.619965</td>\n",
       "      <td>0.608483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726470</td>\n",
       "      <td>0.092678</td>\n",
       "      <td>0.098598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO2am</th>\n",
       "      <td>0.802885</td>\n",
       "      <td>0.589155</td>\n",
       "      <td>0.726470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148181</td>\n",
       "      <td>0.147951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.140665</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.092678</td>\n",
       "      <td>0.148181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_capita</th>\n",
       "      <td>0.145777</td>\n",
       "      <td>0.036684</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>0.147951</td>\n",
       "      <td>0.998241</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                COam     PPMam     SO2am     NO2am     count  per_capita\n",
       "COam        1.000000  0.509747  0.619965  0.802885  0.140665    0.145777\n",
       "PPMam       0.509747  1.000000  0.608483  0.589155  0.034015    0.036684\n",
       "SO2am       0.619965  0.608483  1.000000  0.726470  0.092678    0.098598\n",
       "NO2am       0.802885  0.589155  0.726470  1.000000  0.148181    0.147951\n",
       "count       0.140665  0.034015  0.092678  0.148181  1.000000    0.998241\n",
       "per_capita  0.145777  0.036684  0.098598  0.147951  0.998241    1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
